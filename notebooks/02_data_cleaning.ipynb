{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As discovered in the initial data exploration stage, there are a lot of missing values in my dataset.\n",
    "\n",
    "I will need to clean my dataset in order to ensure my analysis is accurate and all of the necessary data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/tuite/Desktop/Software Portfolio/python/Traffic_Accident_Analysis/data/US_Accidents_March23.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display missing values\n",
    "\n",
    "First I have to display all of the missing values in my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Each Column:\n",
      "              Column Name  Missing Values\n",
      "0                      ID               0\n",
      "1                  Source               0\n",
      "2                Severity               0\n",
      "3              Start_Time               0\n",
      "4                End_Time               0\n",
      "5               Start_Lat               0\n",
      "6               Start_Lng               0\n",
      "7                 End_Lat         3402762\n",
      "8                 End_Lng         3402762\n",
      "9            Distance(mi)               0\n",
      "10            Description               5\n",
      "11                 Street           10869\n",
      "12                   City             253\n",
      "13                 County               0\n",
      "14                  State               0\n",
      "15                Zipcode            1915\n",
      "16                Country               0\n",
      "17               Timezone            7808\n",
      "18           Airport_Code           22635\n",
      "19      Weather_Timestamp          120228\n",
      "20         Temperature(F)          163853\n",
      "21          Wind_Chill(F)         1999019\n",
      "22            Humidity(%)          174144\n",
      "23           Pressure(in)          140679\n",
      "24         Visibility(mi)          177098\n",
      "25         Wind_Direction          175206\n",
      "26        Wind_Speed(mph)          571233\n",
      "27      Precipitation(in)         2203586\n",
      "28      Weather_Condition          173459\n",
      "29                Amenity               0\n",
      "30                   Bump               0\n",
      "31               Crossing               0\n",
      "32               Give_Way               0\n",
      "33               Junction               0\n",
      "34                No_Exit               0\n",
      "35                Railway               0\n",
      "36             Roundabout               0\n",
      "37                Station               0\n",
      "38                   Stop               0\n",
      "39        Traffic_Calming               0\n",
      "40         Traffic_Signal               0\n",
      "41           Turning_Loop               0\n",
      "42         Sunrise_Sunset           23246\n",
      "43         Civil_Twilight           23246\n",
      "44      Nautical_Twilight           23246\n",
      "45  Astronomical_Twilight           23246\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "missing_values_df = pd.DataFrame({'Column Name': missing_values.index, 'Missing Values': missing_values.values})\n",
    "\n",
    "# Display the missing values for all columns\n",
    "print(\"Missing Values in Each Column:\")\n",
    "print(missing_values_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Most of the main collums I will be needing for this project have no missing values, but there are some that I might need to use.\n",
    "\n",
    "I will start by dropping values that have too much missing values, making them unreliable, and also dropping any non relavent collumns for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['ID', 'Description', 'End_Lat', 'End_Lng', 'Country', 'End_Time']\n",
    "df_cleaned = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "Convert data types.\n",
    "\n",
    "-Start_Time should be converted to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743166\n",
      "          Source  Severity Start_Time  Start_Lat   Start_Lng  Distance(mi)  \\\n",
      "3639775  Source1         2        NaT   34.06265 -118.000680         0.049   \n",
      "3639776  Source1         4        NaT   33.93146 -118.390730         0.590   \n",
      "3639777  Source1         3        NaT   33.61789 -117.711160         0.591   \n",
      "3639778  Source1         3        NaT   33.69759 -117.940060         0.287   \n",
      "3639779  Source1         3        NaT   34.03534 -118.329820         0.446   \n",
      "3639780  Source1         2        NaT   34.23274 -118.472990         0.415   \n",
      "3639781  Source1         4        NaT   34.49849 -117.746219         0.070   \n",
      "3639782  Source1         4        NaT   34.49848 -117.747457         0.070   \n",
      "3639783  Source1         2        NaT   37.58130 -122.325460         0.174   \n",
      "3639784  Source1         2        NaT   38.57351 -121.581740         0.232   \n",
      "\n",
      "                   Street             City       County State  ... Roundabout  \\\n",
      "3639775           I-605 S     Baldwin Park  Los Angeles    CA  ...      False   \n",
      "3639776           I-105 W      Los Angeles  Los Angeles    CA  ...      False   \n",
      "3639777   San Diego Fwy S     Laguna Hills       Orange    CA  ...      False   \n",
      "3639778   San Diego Fwy S  Fountain Valley       Orange    CA  ...      False   \n",
      "3639779            I-10 W      Los Angeles  Los Angeles    CA  ...      False   \n",
      "3639780           I-405 N      North Hills  Los Angeles    CA  ...      False   \n",
      "3639781   Pearblossom Hwy            Llano  Los Angeles    CA  ...      False   \n",
      "3639782   Pearblossom Hwy            Llano  Los Angeles    CA  ...      False   \n",
      "3639783    Bayshore Fwy S        San Mateo    San Mateo    CA  ...      False   \n",
      "3639784            I-80 E  West Sacramento         Yolo    CA  ...      False   \n",
      "\n",
      "        Station   Stop Traffic_Calming  Traffic_Signal  Turning_Loop  \\\n",
      "3639775   False  False           False           False         False   \n",
      "3639776   False  False           False           False         False   \n",
      "3639777   False  False           False           False         False   \n",
      "3639778   False  False           False           False         False   \n",
      "3639779   False  False           False           False         False   \n",
      "3639780   False  False           False           False         False   \n",
      "3639781   False  False           False           False         False   \n",
      "3639782   False  False           False           False         False   \n",
      "3639783   False  False           False           False         False   \n",
      "3639784   False  False           False           False         False   \n",
      "\n",
      "         Sunrise_Sunset  Civil_Twilight  Nautical_Twilight  \\\n",
      "3639775           Night           Night              Night   \n",
      "3639776           Night           Night                Day   \n",
      "3639777           Night             Day                Day   \n",
      "3639778             Day             Day                Day   \n",
      "3639779             Day             Day                Day   \n",
      "3639780             Day             Day                Day   \n",
      "3639781             Day             Day                Day   \n",
      "3639782             Day             Day                Day   \n",
      "3639783             Day             Day                Day   \n",
      "3639784             Day             Day                Day   \n",
      "\n",
      "        Astronomical_Twilight  \n",
      "3639775                   Day  \n",
      "3639776                   Day  \n",
      "3639777                   Day  \n",
      "3639778                   Day  \n",
      "3639779                   Day  \n",
      "3639780                   Day  \n",
      "3639781                   Day  \n",
      "3639782                   Day  \n",
      "3639783                   Day  \n",
      "3639784                   Day  \n",
      "\n",
      "[10 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert datetime columns\n",
    "df_cleaned['Start_Time'] = pd.to_datetime(df_cleaned['Start_Time'], errors='coerce')\n",
    "\n",
    "# check for missign values in the start time collumn\n",
    "print(df_cleaned['Start_Time'].isna().sum())\n",
    "\n",
    "# checking the first 10 rows with NaT values\n",
    "print(df_cleaned[df_cleaned['Start_Time'].isna()].head(10))\n",
    "\n",
    "# Drop rows where 'Start_Time' is missing\n",
    "df_cleaned = df_cleaned.dropna(subset=['Start_Time'])\n",
    "\n",
    "# Convert Start time column to date time\n",
    "df_cleaned['Start_Time'] = pd.to_datetime(df_cleaned['Start_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The start time collumn had a lot of missing values so I was having trouble converting to datetime.\n",
    "\n",
    "I want to use start time in my project so I decided to just drop the missing values instead of dropping the whole collumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "Fill missing values for other collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for other columns without using inplace=True\n",
    "df_cleaned['Zipcode'] = df_cleaned['Zipcode'].fillna(df_cleaned['Zipcode'].mode()[0])  # Fill with most common Zipcode\n",
    "df_cleaned['Timezone'] = df_cleaned['Timezone'].fillna(df_cleaned['Timezone'].mode()[0])  # Fill with most common Timezone\n",
    "df_cleaned['Airport_Code'] = df_cleaned['Airport_Code'].fillna('Unknown')  # Replace missing Airport Codes with 'Unknown'\n",
    "df_cleaned['Weather_Timestamp'] = df_cleaned['Weather_Timestamp'].ffill()  # Forward-fill weather timestamps\n",
    "df_cleaned['Temperature(F)'] = df_cleaned['Temperature(F)'].fillna(df_cleaned['Temperature(F)'].median())  # Fill with median temp\n",
    "df_cleaned['Wind_Chill(F)'] = df_cleaned['Wind_Chill(F)'].fillna(df_cleaned['Wind_Chill(F)'].median())  # Fill with median wind chill\n",
    "df_cleaned['Humidity(%)'] = df_cleaned['Humidity(%)'].fillna(df_cleaned['Humidity(%)'].median())  # Fill with median humidity\n",
    "df_cleaned['Pressure(in)'] = df_cleaned['Pressure(in)'].fillna(df_cleaned['Pressure(in)'].median())  # Fill with median pressure\n",
    "df_cleaned['Visibility(mi)'] = df_cleaned['Visibility(mi)'].fillna(df_cleaned['Visibility(mi)'].median())  # Fill with median visibility\n",
    "df_cleaned['Wind_Speed(mph)'] = df_cleaned['Wind_Speed(mph)'].fillna(df_cleaned['Wind_Speed(mph)'].median())  # Fill with median wind speed\n",
    "df_cleaned['Precipitation(in)'] = df_cleaned['Precipitation(in)'].fillna(0)  # Assume no precipitation if missing\n",
    "df_cleaned['Weather_Condition'] = df_cleaned['Weather_Condition'].fillna('Unknown')  # Replace missing weather conditions with 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "My missing values should all be handled.\n",
    "\n",
    "I will confirm this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "Source                        0\n",
      "Severity                      0\n",
      "Start_Time                    0\n",
      "Start_Lat                     0\n",
      "Start_Lng                     0\n",
      "Distance(mi)                  0\n",
      "Street                     8474\n",
      "City                        226\n",
      "County                        0\n",
      "State                         0\n",
      "Zipcode                       0\n",
      "Timezone                      0\n",
      "Airport_Code                  0\n",
      "Weather_Timestamp             0\n",
      "Temperature(F)                0\n",
      "Wind_Chill(F)                 0\n",
      "Humidity(%)                   0\n",
      "Pressure(in)                  0\n",
      "Visibility(mi)                0\n",
      "Wind_Direction           153449\n",
      "Wind_Speed(mph)               0\n",
      "Precipitation(in)             0\n",
      "Weather_Condition             0\n",
      "Amenity                       0\n",
      "Bump                          0\n",
      "Crossing                      0\n",
      "Give_Way                      0\n",
      "Junction                      0\n",
      "No_Exit                       0\n",
      "Railway                       0\n",
      "Roundabout                    0\n",
      "Station                       0\n",
      "Stop                          0\n",
      "Traffic_Calming               0\n",
      "Traffic_Signal                0\n",
      "Turning_Loop                  0\n",
      "Sunrise_Sunset            17560\n",
      "Civil_Twilight            17560\n",
      "Nautical_Twilight         17560\n",
      "Astronomical_Twilight     17560\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm missing values are handled\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Unfortunatelty there are still some missing values remaining.\n",
    "\n",
    "I will need to either fill the values or drop if I will not be needing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle 'Street' and 'City' missing values\n",
    "df_cleaned['Street'] = df_cleaned['Street'].fillna('Unknown')\n",
    "df_cleaned['City'] = df_cleaned['City'].fillna('Unknown')\n",
    "\n",
    "# Handle 'Wind_Direction' missing values\n",
    "df_cleaned['Wind_Direction'] = df_cleaned['Wind_Direction'].fillna('Unknown')\n",
    "\n",
    "# Handle time-related columns (fill with most frequent values)\n",
    "df_cleaned['Sunrise_Sunset'] = df_cleaned['Sunrise_Sunset'].fillna(df_cleaned['Sunrise_Sunset'].mode()[0])\n",
    "df_cleaned['Civil_Twilight'] = df_cleaned['Civil_Twilight'].fillna(df_cleaned['Civil_Twilight'].mode()[0])\n",
    "df_cleaned['Nautical_Twilight'] = df_cleaned['Nautical_Twilight'].fillna(df_cleaned['Nautical_Twilight'].mode()[0])\n",
    "df_cleaned['Astronomical_Twilight'] = df_cleaned['Astronomical_Twilight'].fillna(df_cleaned['Astronomical_Twilight'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after final cleaning:\n",
      "Source                   0\n",
      "Severity                 0\n",
      "Start_Time               0\n",
      "Start_Lat                0\n",
      "Start_Lng                0\n",
      "Distance(mi)             0\n",
      "Street                   0\n",
      "City                     0\n",
      "County                   0\n",
      "State                    0\n",
      "Zipcode                  0\n",
      "Timezone                 0\n",
      "Airport_Code             0\n",
      "Weather_Timestamp        0\n",
      "Temperature(F)           0\n",
      "Wind_Chill(F)            0\n",
      "Humidity(%)              0\n",
      "Pressure(in)             0\n",
      "Visibility(mi)           0\n",
      "Wind_Direction           0\n",
      "Wind_Speed(mph)          0\n",
      "Precipitation(in)        0\n",
      "Weather_Condition        0\n",
      "Amenity                  0\n",
      "Bump                     0\n",
      "Crossing                 0\n",
      "Give_Way                 0\n",
      "Junction                 0\n",
      "No_Exit                  0\n",
      "Railway                  0\n",
      "Roundabout               0\n",
      "Station                  0\n",
      "Stop                     0\n",
      "Traffic_Calming          0\n",
      "Traffic_Signal           0\n",
      "Turning_Loop             0\n",
      "Sunrise_Sunset           0\n",
      "Civil_Twilight           0\n",
      "Nautical_Twilight        0\n",
      "Astronomical_Twilight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm no missing values remain\n",
    "print(\"Missing values after final cleaning:\")\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cleaned!!\n",
    "\n",
    "There are no longer any missing values in my dataset.\n",
    "\n",
    "I will now save the cleaned dataset to a new file that i can use for my project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed! ðŸš€ Cleaned data saved as 'final_cleaned_accident_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the final cleaned dataset\n",
    "df_cleaned.to_csv(\"final_cleaned_accident_data.csv\", index=False)\n",
    "print(\"Data cleaning completed! ðŸš€ Cleaned data saved as 'final_cleaned_accident_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, I focused on cleaning the traffic accident dataset to ensure it was ready for further analysis and visualization. The cleaning process involved several key steps:\n",
    "\n",
    "- Handling missing data:\n",
    "    For categorical columns like 'Zipcode' and 'Timezone', I filled missing entries with the most common value and replaced missing values with meaningful defaults for other columns.\n",
    "- correcting datatypes:\n",
    "    I converted columns like 'Start_Time' to datetime format and ensured numerical columns were properly formatted for analysis.\n",
    "- removing irrelevent data:\n",
    "    I removed or replaced irrelevent records, mainly for columns with impossible or unrealistic values, ensuring the dataset was accurate and reliable for analysis.\n",
    "\n",
    "- Challenges faced:\n",
    "    I ran into some errors when trying to convert datatype of start time collumn as there was a lot of missing values.\n",
    "    I had to drop a lot more collumns than i had initially thought but luckily most of the data was irrelevent to my project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "With the dataset now clean, the next step will be to proceed with data exploration and visualization, particularly creating heatmaps of accident locations and applying machine learning models to predict accident severity. Further data imputation could also be explored if additional data becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accident_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
